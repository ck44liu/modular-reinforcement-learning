{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up Functions for all Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Randomly initialize the environment, note that we first generate litters and then obstacles. In this way,\n",
    "# some of the obstacles may overwrite some grids with litters, but that is not an issue as our environment\n",
    "# and setup number of litters and obstacles are large enough.\n",
    "def init_env(r=8, c=16, rand=-1):\n",
    "    environ = np.empty(shape=(r, c), dtype=str)\n",
    "    environ.fill('0')\n",
    "\n",
    "    # $ for litter\n",
    "    rng = np.random.default_rng()\n",
    "    lit_x = rng.integers(0, r, 20)\n",
    "    lit_y = rng.integers(0, c, 20)\n",
    "    for i in range(20):\n",
    "        environ[lit_x[i], lit_y[i]] = '$'\n",
    "    # x for obstacle\n",
    "    obs_x = rng.integers(0, r, 20)\n",
    "    obs_y = rng.integers(0, c, 20)\n",
    "    for i in range(20):\n",
    "        environ[obs_x[i], obs_y[i]] = 'x'\n",
    "\n",
    "    # a for agent\n",
    "    ac = 0\n",
    "    ar = rng.integers(0, 8) if rand == -1 else rand\n",
    "\n",
    "    environ[ar, ac] = 'a'\n",
    "    # environ[5, 15] = 'g'\n",
    "    return environ, ar\n",
    "\n",
    "\n",
    "# extract enviroment with only agent location, used for sidewalk and goal module learning\n",
    "def env_extract(a_r, r=8, c=16):\n",
    "    extract_env = np.empty(shape=(r, c), dtype=str)\n",
    "    extract_env.fill('0')\n",
    "    extract_env[a_r, 0] = 'a'\n",
    "    return extract_env\n",
    "\n",
    "\n",
    "# extract environment with only agent and litter locations, used for litter module learning\n",
    "def env_extract_litter(env, a_r, r=8, c=16):\n",
    "    extract_env = np.empty(shape=(r, c), dtype=str)\n",
    "    extract_env.fill('0')\n",
    "\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if env[i, j] == '$':\n",
    "                extract_env[i, j] = '$'\n",
    "\n",
    "    extract_env[a_r, 0] = 'a'\n",
    "    return extract_env\n",
    "\n",
    "\n",
    "# extract environment with only agent and obstacle locations, used for obstacle module learning\n",
    "def env_extract_obs(env, a_r, r=8, c=16):\n",
    "    extract_env = np.empty(shape=(r, c), dtype=str)\n",
    "    extract_env.fill('0')\n",
    "\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            if env[i, j] == 'x':\n",
    "                extract_env[i, j] = 'x'\n",
    "\n",
    "    extract_env[a_r, 0] = 'a'\n",
    "    return extract_env\n",
    "\n",
    "\n",
    "# initialize Q-table for each module\n",
    "qtable_sidewalk = np.zeros((8, 4))\n",
    "qtable_goal = np.zeros((8 * 16, 4))\n",
    "qtable_obs = np.zeros((2 ** 6, 4))\n",
    "qtable_lit = np.zeros((2 ** 15, 4))\n",
    "\n",
    "\n",
    "# check if the row is within sidewalk\n",
    "def is_sidewalk(r):\n",
    "    return 2 <= r < 6\n",
    "\n",
    "\n",
    "# setup goal location, we fix it to be [5,15]\n",
    "goal = [5, 15]\n",
    "\n",
    "\n",
    "# check if a grid is goal\n",
    "def is_goal(r, c):\n",
    "    return [r, c] == goal\n",
    "\n",
    "\n",
    "# check if a grid is obstacle\n",
    "def is_obstacle(r, c, environ):\n",
    "    return environ[r, c] == 'x'\n",
    "\n",
    "\n",
    "# check if a grid is litter\n",
    "def is_litter(r, c, environ):\n",
    "    return environ[r, c] == '$'\n",
    "\n",
    "\n",
    "# get the sum of row distance and column distance between a certain grid and the goal\n",
    "def get_distance(r, c):\n",
    "    return abs(r - goal[0]) + abs(c - goal[1])\n",
    "\n",
    "\n",
    "# get corresponding state number of sidewalk module\n",
    "def get_state_sd(r):\n",
    "    return r\n",
    "\n",
    "\n",
    "# get corresponding state number of goal module\n",
    "def get_state_goal(r, c):\n",
    "    return r * 16 + c\n",
    "\n",
    "\n",
    "# get state number from the encoded binary list for obstable module\n",
    "def get_state_obs_num(ls, len=6):\n",
    "    sum = 0\n",
    "    for i in range(len):\n",
    "        power = len - i - 1\n",
    "        sum += ls[i] * (2 ** power)\n",
    "    return sum\n",
    "\n",
    "\n",
    "# get corresponding state number of obstacle module\n",
    "def get_state_obs(environ, ar, ac):\n",
    "    ls = []\n",
    "    for i in range(ar - 1, ar + 2):\n",
    "        for j in range(ac, ac + 2):\n",
    "            if out_bound(i, j):\n",
    "                ls.append(0)\n",
    "            else:\n",
    "                ls.append(int(environ[i, j] == 'x'))\n",
    "    s = get_state_obs_num(ls)\n",
    "    return s\n",
    "\n",
    "\n",
    "# get state number from the encoded binary list for litter module\n",
    "def get_state_lit_num(ls, len=15):\n",
    "    sum = 0\n",
    "    for i in range(len):\n",
    "        power = len - i - 1\n",
    "        sum += ls[i] * (2 ** power)\n",
    "    return sum\n",
    "\n",
    "\n",
    "# get corresponding state number of litter module\n",
    "def get_state_lit(environ, ar, ac):\n",
    "    ls = []\n",
    "    for i in range(ar - 2, ar + 3):\n",
    "        for j in range(ac, ac + 3):\n",
    "            if out_bound(i, j):\n",
    "                ls.append(0)\n",
    "            else:\n",
    "                ls.append(int(environ[i, j] == '$'))\n",
    "    s = get_state_lit_num(ls)\n",
    "    return s\n",
    "\n",
    "\n",
    "# check if a location is out of boundary\n",
    "def out_bound(r, c):\n",
    "    return r < 0 or r > 7 or c < 0 or c > 15\n",
    "\n",
    "\n",
    "# Setup reward function for each module\n",
    "\n",
    "def get_reward_sd(r):\n",
    "    return 30 if is_sidewalk(r) else -500\n",
    "\n",
    "\n",
    "def get_reward_goal(r, c, new_r, new_c):\n",
    "    if get_distance(r, c) == 0:\n",
    "        return 100000\n",
    "\n",
    "    dist = get_distance(r, c) - get_distance(new_r, new_c)\n",
    "    if dist <= 0:\n",
    "        return -400\n",
    "    else:\n",
    "        return 200\n",
    "\n",
    "\n",
    "def get_reward_obs(environ, r, c):\n",
    "    if out_bound(r, c) or environ[r, c] != 'x':\n",
    "        return 5\n",
    "    else:\n",
    "        return -5000\n",
    "\n",
    "\n",
    "def get_reward_lit(environ, r, c):\n",
    "    if out_bound(r, c) or environ[r, c] != '$':\n",
    "        return -1\n",
    "    else:\n",
    "        return 500\n",
    "\n",
    "\n",
    "# set dictionary to represent 4 different moving directions\n",
    "direct = {0: [-1, 0], 1: [0, 1], 2: [1, 0], 3: [0, -1]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sidewalk Module Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' 'a' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']]\n",
      "[[2, 0], [1, 0], [0, 0], [0, 0], [0, 0], [0, 1], [1, 1], [1, 2], [2, 2], [2, 3], [3, 3], [4, 3], [4, 2], [5, 2], [5, 1], [5, 0], [5, 0], [4, 0], [5, 0], [6, 0], [5, 0], [5, 0], [5, 0], [5, 0], [5, 0], [5, 1], [5, 0], [5, 0], [5, 0], [5, 0], [5, 0], [5, 0], [5, 0], [4, 0], [5, 0], [5, 0], [5, 1], [5, 0], [5, 0], [5, 0], [4, 0], [5, 0], [5, 0], [5, 0], [4, 0], [3, 0], [4, 0], [5, 0], [5, 1], [5, 2], [5, 3], [5, 4], [5, 3], [5, 2], [5, 3], [4, 3], [4, 2], [5, 2], [5, 3], [5, 4], [5, 5], [5, 6], [5, 7], [5, 8], [5, 9], [5, 10], [5, 11], [5, 10], [5, 11], [4, 11], [4, 12], [5, 12], [5, 11], [5, 10], [4, 10], [5, 10], [5, 11], [5, 12], [4, 12], [4, 11], [5, 11], [5, 10], [5, 9], [5, 10], [4, 10], [5, 10], [5, 11], [5, 12], [5, 13], [5, 14], [5, 13], [4, 13], [5, 13], [5, 12], [4, 12], [5, 12], [4, 12], [5, 12], [4, 12], [5, 12], [4, 12], [4, 11], [5, 11], [4, 11], [5, 11], [4, 11], [4, 10], [4, 9], [4, 10], [5, 10], [5, 9], [4, 9], [3, 9], [2, 9], [2, 8], [2, 7], [2, 6], [2, 5], [3, 5], [4, 5], [5, 5], [4, 5], [5, 5], [5, 4], [5, 3], [4, 3], [3, 3], [4, 3], [3, 3], [3, 2], [3, 3], [4, 3], [3, 3], [3, 2], [4, 2], [4, 3], [5, 3], [4, 3], [5, 3], [4, 3], [4, 2], [5, 2], [5, 3], [4, 3], [5, 3], [5, 2], [5, 1], [4, 1], [4, 0], [3, 0], [2, 0], [3, 0], [3, 0], [4, 0], [4, 0], [4, 1], [4, 0], [4, 0], [4, 0], [4, 0], [5, 0], [4, 0], [3, 0], [4, 0], [4, 0], [4, 0], [4, 0], [4, 0], [4, 0], [4, 0], [4, 0], [4, 0], [4, 0], [4, 0], [4, 0], [3, 0], [2, 0], [3, 0], [3, 0], [4, 0], [3, 0], [4, 0], [4, 0], [4, 0], [3, 0], [4, 0], [4, 0], [3, 0], [3, 1], [4, 1], [5, 1], [5, 2], [4, 2], [3, 2], [4, 2], [3, 2], [3, 3], [4, 3], [3, 3], [2, 3], [3, 3]]\n",
      "[['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' 'a']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']]\n",
      "[[1, 0], [2, 0], [2, 1], [3, 1], [2, 1], [2, 2], [2, 3], [2, 4], [2, 3], [2, 4], [2, 5], [2, 6], [2, 5], [2, 4], [2, 5], [3, 5], [4, 5], [5, 5], [5, 6], [4, 6], [3, 6], [3, 5], [3, 4], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [3, 8], [2, 8], [3, 8], [3, 7], [3, 8], [3, 9], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [2, 14], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [3, 15], [3, 14], [3, 15], [2, 15], [2, 15], [2, 14], [2, 13], [2, 12], [2, 13], [2, 14], [2, 13], [3, 13], [3, 12], [3, 11], [3, 10], [2, 10], [2, 11], [2, 12], [3, 12], [3, 13], [3, 14], [3, 13], [2, 13], [2, 14], [2, 13], [2, 14], [2, 15], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 14], [3, 14], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [3, 15], [4, 15], [3, 15], [3, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [3, 15], [2, 15], [2, 15], [2, 14], [2, 13], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [2, 15], [3, 15], [3, 15], [2, 15], [2, 15], [2, 15], [3, 15], [3, 14], [3, 15], [2, 15], [3, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [2, 15], [2, 14], [2, 13], [3, 13], [2, 13], [3, 13], [3, 14], [2, 14], [2, 13], [3, 13], [2, 13], [2, 14], [2, 13], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [2, 15], [3, 15], [2, 15]]\n",
      "[['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' 'a' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']]\n",
      "[[6, 0], [5, 0], [5, 0], [4, 0], [5, 0], [4, 0], [3, 0], [3, 0], [3, 0], [2, 0], [2, 0], [2, 1], [2, 2], [3, 2], [4, 2], [3, 2], [2, 2], [2, 3], [3, 3], [3, 4], [2, 4], [2, 5], [2, 4], [2, 5], [2, 4], [2, 5], [2, 6], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 10], [2, 11], [2, 12], [2, 13], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [3, 14], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [3, 15], [4, 15], [5, 15], [5, 15], [5, 15], [4, 15], [3, 15], [2, 15], [3, 15], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [3, 15], [2, 15], [2, 14], [3, 14], [3, 13], [2, 13], [2, 14], [2, 15], [2, 15], [2, 14], [2, 13], [2, 14], [2, 15], [3, 15], [4, 15], [3, 15], [4, 15], [3, 15], [3, 15], [3, 15], [4, 15], [3, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [2, 15], [2, 15], [3, 15], [3, 14], [2, 14], [3, 14], [3, 13], [4, 13], [3, 13], [2, 13], [3, 13], [3, 12], [2, 12], [3, 12], [2, 12], [2, 13], [2, 14], [2, 13], [3, 13], [2, 13], [2, 14], [2, 15], [2, 15], [2, 14], [2, 13], [2, 14], [2, 13], [2, 14], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [2, 15], [2, 14], [3, 14], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [3, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [2, 14], [2, 15], [2, 15], [3, 15], [2, 15], [2, 15], [3, 15], [4, 15], [5, 15], [5, 14], [4, 14], [4, 13], [4, 12]]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 4000  # total number of episodes in learning\n",
    "max_step = 200  # the max number of steps within each episode\n",
    "mu = 0.9  # learning rate\n",
    "gamma = 0.9  # discount factor\n",
    "epsilon = 0.5  # value for epsilon-greedy algorithm\n",
    "for num in range(num_episodes):\n",
    "    env, a_r = init_env()\n",
    "    environ_sd = env_extract(a_r)\n",
    "    a_c = 0\n",
    "\n",
    "    loc = [[a_r, a_c]]\n",
    "    s = get_state_sd(a_r)\n",
    "    new_s = s\n",
    "\n",
    "    for j in range(max_step):\n",
    "        # epsilon-greedy algorithm\n",
    "        greedy = False\n",
    "        indices = 0\n",
    "        if np.random.rand() < epsilon:\n",
    "            indices = np.where(qtable_sidewalk[s, :] >= 0)\n",
    "            if np.shape(indices)[1] != 0:\n",
    "                greedy = True\n",
    "\n",
    "        if greedy:\n",
    "            pick = np.random.randint(np.shape(indices)[1])\n",
    "            act = indices[0][pick]\n",
    "        else:\n",
    "            act = np.argmax(qtable_sidewalk[s, :])\n",
    "\n",
    "        row = a_r + direct[act][0]\n",
    "        col = a_c + direct[act][1]\n",
    "        r = get_reward_sd(row)\n",
    "\n",
    "        # perform action\n",
    "        if act == 0:  # up\n",
    "            if not out_bound(a_r - 1, a_c):\n",
    "                environ_sd[a_r, a_c] = '0'\n",
    "                environ_sd[a_r - 1, a_c] = 'a'\n",
    "                new_s = get_state_sd(a_r - 1)\n",
    "                a_r -= 1\n",
    "        if act == 1:  # right\n",
    "            if not out_bound(a_r, a_c + 1):\n",
    "                environ_sd[a_r, a_c] = '0'\n",
    "                environ_sd[a_r, a_c + 1] = 'a'\n",
    "                new_s = get_state_sd(a_r)\n",
    "                a_c += 1\n",
    "        if act == 2:  # down\n",
    "            if not out_bound(a_r + 1, a_c):\n",
    "                environ_sd[a_r, a_c] = '0'\n",
    "                environ_sd[a_r + 1, a_c] = 'a'\n",
    "                new_s = get_state_sd(a_r + 1)\n",
    "                a_r += 1\n",
    "        if act == 3:  # left\n",
    "            if not out_bound(a_r, a_c - 1):\n",
    "                environ_sd[a_r, a_c] = '0'\n",
    "                environ_sd[a_r, a_c - 1] = 'a'\n",
    "                new_s = get_state_sd(a_r)\n",
    "                a_c -= 1\n",
    "        \n",
    "        # updata with Q-learning\n",
    "        loc.append([a_r, a_c])\n",
    "        qtable_sidewalk[s, act] += mu * (r + gamma * max(qtable_sidewalk[new_s, :]) - qtable_sidewalk[s, act])\n",
    "        s = new_s\n",
    "\n",
    "    # print environment and agent's trajectory in certain episode numbers\n",
    "    if num == 0 or num == num_episodes // 2 or num == num_episodes - 1:\n",
    "        print(environ_sd)\n",
    "        print(loc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Print Sidewalk Module Q-table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_sd:\n",
      " [[-859.5        -859.5        -230.         -450.        ]\n",
      " [-450.         -450.          300.         -207.22114766]\n",
      " [-450.          300.          300.          300.        ]\n",
      " [ 300.          300.          300.          300.        ]\n",
      " [ 300.          300.          300.          300.        ]\n",
      " [ 300.          300.         -450.          300.        ]\n",
      " [ 300.         -207.00017263 -634.43979653 -207.17262538]\n",
      " [-230.         -450.         -450.         -450.        ]]\n"
     ]
    }
   ],
   "source": [
    "print('q_sd:\\n', qtable_sidewalk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Goal Module Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' 'a']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']]\n",
      "[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [0, 13], [0, 14], [0, 15], [1, 15], [2, 15], [3, 15], [4, 15], [5, 15]]\n",
      "[['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' 'a']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']]\n",
      "[[1, 0], [1, 1], [1, 2], [1, 3], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [0, 13], [0, 14], [0, 15], [1, 15], [2, 15], [3, 15], [4, 15], [5, 15]]\n",
      "[['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' 'a']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']]\n",
      "[[0, 0], [0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10], [0, 11], [0, 12], [0, 13], [0, 14], [0, 15], [1, 15], [2, 15], [3, 15], [4, 15], [5, 15]]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 4000\n",
    "max_step = 50\n",
    "mu = 0.8\n",
    "gamma = 0.9\n",
    "epsilon = 0.01\n",
    "for num in range(num_episodes):\n",
    "    env, a_r = init_env()\n",
    "    env_goal = env_extract(a_r)\n",
    "    # rng = np.random.default_rng()\n",
    "    a_c = 0\n",
    "\n",
    "    loc = [[a_r, a_c]]\n",
    "    s = get_state_goal(a_r, a_c)\n",
    "    new_s = s\n",
    "\n",
    "    for j in range(max_step):\n",
    "        if is_goal(a_r, a_c):\n",
    "            break\n",
    "\n",
    "        # epsilon-greedy algorithm\n",
    "        greedy = False\n",
    "        indices = 0\n",
    "        if np.random.rand() < epsilon:\n",
    "            indices = np.where(qtable_goal[s, :] > 0)\n",
    "            if np.shape(indices)[1] != 0:\n",
    "                greedy = True\n",
    "\n",
    "        if greedy:\n",
    "            pick = np.random.randint(np.shape(indices)[1])\n",
    "            act = indices[0][pick]\n",
    "        else:\n",
    "            act = np.argmax(qtable_goal[s, :])\n",
    "\n",
    "        row = a_r + direct[act][0]\n",
    "        col = a_c + direct[act][1]\n",
    "        r = get_reward_goal(a_r, a_c, row, col)\n",
    "\n",
    "        # perform action\n",
    "        if act == 0:  # up\n",
    "            if not out_bound(a_r - 1, a_c):\n",
    "                env_goal[a_r, a_c] = '0'\n",
    "                env_goal[a_r - 1, a_c] = 'a'\n",
    "                new_s = get_state_goal(a_r - 1, a_c)\n",
    "                a_r -= 1\n",
    "        if act == 1:  # right\n",
    "            if not out_bound(a_r, a_c + 1):\n",
    "                env_goal[a_r, a_c] = '0'\n",
    "                env_goal[a_r, a_c + 1] = 'a'\n",
    "                new_s = get_state_goal(a_r, a_c + 1)\n",
    "                a_c += 1\n",
    "        if act == 2:  # down\n",
    "            if not out_bound(a_r + 1, a_c):\n",
    "                env_goal[a_r, a_c] = '0'\n",
    "                env_goal[a_r + 1, a_c] = 'a'\n",
    "                new_s = get_state_goal(a_r + 1, a_c)\n",
    "                a_r += 1\n",
    "        if act == 3:  # left\n",
    "            if not out_bound(a_r, a_c - 1):\n",
    "                env_goal[a_r, a_c] = '0'\n",
    "                env_goal[a_r, a_c - 1] = 'a'\n",
    "                new_s = get_state_goal(a_r, a_c - 1)\n",
    "                a_c -= 1\n",
    "\n",
    "        # update with Q-learning\n",
    "        loc.append([a_r, a_c])\n",
    "        qtable_goal[s, act] += mu * (r + gamma * max(qtable_goal[new_s, :]) - qtable_goal[s, act])\n",
    "        s = new_s\n",
    "\n",
    "    # print environment and agent's trajectory in certain episode numbers\n",
    "    if num == 0 or num == num_episodes // 2 or num == num_episodes - 1:\n",
    "        print(env_goal)\n",
    "        print(loc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Examine Rows of Goal Module Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-values at [2,0]:  [-320.         1699.81072941    0.            0.        ]\n",
      "Q-values at [5,0]:  [-320.         1180.45636601    0.            0.        ]\n",
      "Q-values at [7,0]:  [1336.16965647    0.            0.            0.        ]\n",
      "Q-values at [3,10]: [-320.        831.499022    0.          0.      ]\n",
      "Q-values at [5,14]: [0. 0. 0. 0.]\n",
      "Q-values at [4,15]: [-204.8 -320.   200.     0. ]\n"
     ]
    }
   ],
   "source": [
    "print('Q-values at [2,0]: ', qtable_goal[get_state_goal(2,0), :])\n",
    "print('Q-values at [5,0]: ', qtable_goal[get_state_goal(5,0), :])\n",
    "print('Q-values at [7,0]: ', qtable_goal[get_state_goal(7,0), :])\n",
    "print('Q-values at [3,10]:', qtable_goal[get_state_goal(3,10), :])\n",
    "print('Q-values at [5,14]:', qtable_goal[get_state_goal(5,14), :])\n",
    "print('Q-values at [4,15]:', qtable_goal[get_state_goal(4,15), :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obstacle Module Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' 'x' 'x' '0' '0' '0' '0' '0' '0' 'x' '0' '0' '0' '0' 'a' 'x']\n",
      " ['0' '0' '0' '0' '0' 'x' '0' 'x' '0' '0' '0' 'x' '0' '0' 'x' 'x']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' 'x' '0' '0' '0' 'x' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' 'x' '0' '0' '0' '0' '0' 'x' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' 'x' '0']\n",
      " ['x' '0' 'x' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' 'x' 'x' 'x' '0' '0']]\n",
      "[[5, 0], [4, 0], [3, 0], [2, 0], [1, 0], [1, 1], [1, 2], [1, 3], [0, 3], [0, 3], [0, 4], [0, 4], [0, 4], [0, 4], [1, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [0, 4], [1, 4], [0, 4], [0, 4], [1, 4], [0, 4], [0, 4], [0, 4], [0, 5], [0, 5], [0, 6], [0, 6], [0, 6], [0, 6], [0, 6], [0, 6], [0, 6], [0, 6], [0, 6], [0, 6], [1, 6], [0, 6], [0, 6], [0, 6], [0, 6], [0, 7], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [2, 8], [3, 8], [2, 8], [3, 8], [2, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [1, 8], [2, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [2, 8], [2, 9], [1, 9], [2, 9], [1, 9], [1, 10], [0, 10], [0, 10], [0, 11], [0, 11], [0, 11], [0, 12], [0, 12], [0, 12], [0, 12], [0, 12], [0, 12], [0, 13], [0, 14], [0, 14], [0, 14], [0, 14]]\n",
      "[['0' '0' 'x' '0' '0' '0' '0' '0' '0' 'x' '0' '0' '0' '0' '0' '0']\n",
      " ['x' '0' '0' '0' '0' '0' '0' '0' 'a' 'x' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' 'x' '0' 'x' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' 'x' '0' '0' '0' '0' '0' '0']\n",
      " ['x' '0' 'x' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['x' '0' '0' 'x' '0' '0' '0' '0' '0' '0' '0' '0' 'x' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' 'x' '0' '0' 'x' '0' '0' '0' '0' 'x' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']]\n",
      "[[3, 0], [2, 0], [2, 1], [3, 1], [2, 1], [1, 1], [0, 1], [1, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [1, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [1, 1], [1, 2], [1, 3], [0, 3], [0, 3], [0, 3], [0, 3], [0, 3], [1, 3], [0, 3], [0, 3], [0, 3], [0, 3], [0, 3], [1, 3], [0, 3], [0, 3], [0, 3], [0, 3], [0, 3], [1, 3], [0, 3], [0, 4], [0, 4], [0, 4], [0, 4], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [1, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [1, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [1, 5], [0, 5], [1, 5], [1, 6], [0, 6], [0, 6], [0, 6], [0, 7], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [1, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [2, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [2, 8], [3, 8], [2, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [0, 8], [1, 8]]\n",
      "[['0' 'x' '0' '0' 'x' '0' 'x' 'x' '0' '0' '0' '0' '0' '0' '0' 'a']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' 'x' 'x' 'x' '0' '0' '0' 'x']\n",
      " ['0' '0' '0' '0' '0' 'x' '0' 'x' '0' '0' '0' '0' '0' 'x' '0' 'x']\n",
      " ['0' '0' '0' '0' 'x' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' 'x' '0' '0' '0' '0' '0' '0' '0' 'x' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' 'x' '0' '0' '0' '0' '0' '0' 'x']\n",
      " ['0' '0' 'x' 'x' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']]\n",
      "[[0, 0], [0, 0], [1, 0], [2, 0], [1, 0], [1, 1], [1, 2], [0, 2], [0, 2], [0, 2], [0, 2], [0, 3], [0, 3], [1, 3], [1, 4], [1, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [0, 5], [1, 5], [0, 5], [1, 5], [1, 6], [2, 6], [3, 6], [2, 6], [1, 6], [1, 7], [1, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [1, 8], [0, 8], [0, 8], [0, 8], [0, 9], [0, 9], [0, 9], [0, 9], [0, 9], [0, 9], [0, 9], [0, 9], [0, 9], [0, 9], [0, 10], [0, 10], [0, 10], [0, 10], [0, 10], [0, 10], [0, 10], [0, 10], [0, 10], [0, 11], [0, 11], [0, 12], [0, 12], [1, 12], [1, 13], [0, 13], [0, 13], [1, 13], [0, 13], [0, 13], [0, 13], [0, 13], [0, 13], [0, 13], [0, 13], [0, 13], [0, 14], [0, 14], [0, 14], [0, 14], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15], [0, 15]]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 4000\n",
    "max_step = 200\n",
    "mu = 0.8\n",
    "gamma = 0.9\n",
    "epsilon = 0.33\n",
    "for num in range(num_episodes):\n",
    "    env, a_r = init_env()\n",
    "    environ_agent = env_extract(a_r)\n",
    "    environ_obs = env_extract_obs(env, a_r)\n",
    "    a_c = 0\n",
    "\n",
    "    loc = [[a_r, a_c]]\n",
    "    s = get_state_obs(environ_obs, a_r, a_c)\n",
    "    new_s = s\n",
    "\n",
    "    for j in range(max_step):\n",
    "        # epsilon-greedy algorithm\n",
    "        greedy = False\n",
    "        indices = 0\n",
    "        if np.random.rand() < epsilon:\n",
    "            indices = np.where(qtable_obs[s, :] > -50)\n",
    "            if np.shape(indices)[1] != 0:\n",
    "                greedy = True\n",
    "\n",
    "        if greedy:\n",
    "            pick = np.random.randint(np.shape(indices)[1])\n",
    "            act = indices[0][pick]\n",
    "        else:\n",
    "            act = np.argmax(qtable_obs[s, :])\n",
    "\n",
    "        row = a_r + direct[act][0]\n",
    "        col = a_c + direct[act][1]\n",
    "        r = get_reward_obs(environ_obs, row, col)\n",
    "\n",
    "        # perform action\n",
    "        if act == 0:  # up\n",
    "            if not out_bound(a_r - 1, a_c):\n",
    "                environ_agent[a_r, a_c] = '0'\n",
    "                environ_agent[a_r - 1, a_c] = 'a'\n",
    "                new_s = get_state_obs(environ_obs, a_r - 1, a_c)\n",
    "                a_r -= 1\n",
    "        if act == 1:  # right\n",
    "            if not out_bound(a_r, a_c + 1):\n",
    "                environ_agent[a_r, a_c] = '0'\n",
    "                environ_agent[a_r, a_c + 1] = 'a'\n",
    "                new_s = get_state_obs(environ_obs, a_r, a_c + 1)\n",
    "                a_c += 1\n",
    "        if act == 2:  # down\n",
    "            if not out_bound(a_r + 1, a_c):\n",
    "                environ_agent[a_r, a_c] = '0'\n",
    "                environ_agent[a_r + 1, a_c] = 'a'\n",
    "                new_s = get_state_obs(environ_obs, a_r + 1, a_c)\n",
    "                a_r += 1\n",
    "        if act == 3:  # left\n",
    "            if not out_bound(a_r, a_c - 1):\n",
    "                environ_agent[a_r, a_c] = '0'\n",
    "                environ_agent[a_r, a_c - 1] = 'a'\n",
    "                new_s = get_state_obs(environ_obs, a_r, a_c - 1)\n",
    "                a_c -= 1\n",
    "\n",
    "        # update with Q-learning\n",
    "        loc.append([a_r, a_c])\n",
    "        qtable_obs[s, act] += mu * (r + gamma * max(qtable_obs[new_s, :]) - qtable_obs[s, act])\n",
    "        s = new_s\n",
    "\n",
    "    # print environment and agent's trajectory in certain episode numbers\n",
    "    if num == 0 or num == num_episodes // 2 or num == num_episodes - 1:\n",
    "        e_r, e_c = 8, 16\n",
    "        e = np.empty(shape=(e_r, e_c), dtype=str)\n",
    "        e.fill('0')\n",
    "\n",
    "        for i in range(e_r):\n",
    "            for j in range(e_c):\n",
    "                if environ_obs[i, j] == 'x':\n",
    "                    e[i, j] = 'x'\n",
    "\n",
    "        e[a_r, a_c] = 'a'\n",
    "        print(e)\n",
    "        print(loc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' 'x']\n",
      " ['0' '0']\n",
      " ['0' 'x']]\n",
      "\n",
      "[['x' 'x']\n",
      " ['0' '0']\n",
      " ['0' 'x']]\n",
      "\n",
      "[['0' '0']\n",
      " ['0' 'x']\n",
      " ['0' '0']]\n",
      "\n",
      "[['x' '0']\n",
      " ['0' 'x']\n",
      " ['x' 'x']]\n",
      "\n",
      "[['x' '0']\n",
      " ['x' '0']\n",
      " ['x' '0']]\n",
      "\n",
      "[['x' 'x']\n",
      " ['x' 'x']\n",
      " ['x' 'x']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print certain obstacle module local 6-gridworlds\n",
    "print(np.array([['0','x'],['0','0'],['0','x']]))\n",
    "print()\n",
    "print(np.array([['x','x'],['0','0'],['0','x']]))\n",
    "print()\n",
    "print(np.array([['0','0'],['0','x'],['0','0']]))\n",
    "print()\n",
    "print(np.array([['x','0'],['0','x'],['x','x']]))\n",
    "print()\n",
    "print(np.array([['x','0'],['x','0'],['x','0']]))\n",
    "print()\n",
    "print(np.array([['x','x'],['x','x'],['x','x']]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(0, 1, 0, 0, 0, 1) --> 17:\n",
      " [   50.     50.     50.  -3961.2]\n",
      "\n",
      "\n",
      "(1, 1, 0, 0, 0, 1) --> 49:\n",
      " [-4000.            50.            50.         -3981.57908404]\n",
      "\n",
      "\n",
      "(0, 0, 0, 1, 0, 0) --> 4:\n",
      " [   50.         -4000.            50.         -3961.34693238]\n",
      "\n",
      "\n",
      "(1, 0, 0, 1, 1, 1) --> 39:\n",
      " [-4000.         -3967.18947019 -3971.2           50.        ]\n",
      "\n",
      "\n",
      "(1, 0, 1, 0, 1, 0) --> 42:\n",
      " [-3964.41192249    42.21312    -3971.2            0.        ]\n",
      "\n",
      "\n",
      "(1, 1, 1, 1, 1, 1) --> 64:\n",
      " [0. 0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the associated obstacle module state number and Q-table entries\n",
    "print()\n",
    "a = (0,1,0,0,0,1)\n",
    "print(a,\"--> 17:\\n\", qtable_obs[17,:])\n",
    "print('\\n')\n",
    "b = (1,1,0,0,0,1)\n",
    "print(b,\"--> 49:\\n\", qtable_obs[49,:])\n",
    "print('\\n')\n",
    "c = (0,0,0,1,0,0)\n",
    "print(c,\"--> 4:\\n\", qtable_obs[4,:])\n",
    "print('\\n')\n",
    "d = (1,0,0,1,1,1)\n",
    "print(d,\"--> 39:\\n\", qtable_obs[39,:])\n",
    "print('\\n')\n",
    "e = (1,0,1,0,1,0)\n",
    "print(e,\"--> 42:\\n\", qtable_obs[42,:])\n",
    "print('\\n')\n",
    "f = (1,1,1,1,1,1)\n",
    "print(f,\"--> 64:\\n\", qtable_obs[63,:])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Litter Module Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '$' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '$' '$' '0' '$' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '$' '0' '0' '$' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' 'a' '0' '0' '0']\n",
      " ['0' '0' '$' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '$' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']]\n",
      "litter picked up: 7\n",
      "[[2, 0], [2, 0], [1, 0], [0, 0], [0, 0], [1, 0], [1, 1], [0, 1], [0, 1], [0, 2], [0, 2], [0, 3], [1, 3], [2, 3], [2, 4], [2, 5], [3, 5], [2, 5], [2, 4], [2, 5], [2, 6], [3, 6], [3, 7], [4, 7], [4, 8], [5, 8], [5, 7], [4, 7], [4, 8], [5, 8], [5, 7], [5, 8], [4, 8], [5, 8], [5, 9], [5, 10], [5, 9], [5, 10], [5, 9], [5, 10], [5, 9], [5, 10], [5, 11], [5, 10], [6, 10], [7, 10], [6, 10], [6, 11], [6, 12], [5, 12], [6, 12], [6, 13], [6, 14], [7, 14], [6, 14], [7, 14], [7, 15], [7, 15], [7, 15], [7, 15], [7, 14], [7, 15], [7, 14], [6, 14], [7, 14], [7, 15], [7, 14], [7, 13], [7, 14], [7, 13], [6, 13], [7, 13], [6, 13], [6, 14], [6, 13], [5, 13], [5, 14], [5, 15], [5, 14], [6, 14], [6, 15], [6, 14], [7, 14], [7, 15], [7, 14], [7, 14], [7, 15], [7, 14], [7, 14], [7, 15], [7, 14], [7, 14], [7, 15], [7, 14], [6, 14], [7, 14], [7, 15], [7, 14], [7, 15], [7, 15], [7, 14], [7, 14], [6, 14], [6, 15], [6, 14], [7, 14], [7, 15], [6, 15], [6, 14], [6, 13], [7, 13], [7, 14], [6, 14], [7, 14], [7, 15], [6, 15], [6, 14], [7, 14], [7, 15], [6, 15], [6, 14], [5, 14], [6, 14], [6, 15], [6, 14], [5, 14], [5, 15], [6, 15], [6, 15], [6, 14], [7, 14], [6, 14], [6, 15], [6, 14], [7, 14], [6, 14], [6, 13], [6, 14], [7, 14], [6, 14], [6, 13], [6, 14], [7, 14], [6, 14], [6, 13], [6, 14], [7, 14], [7, 13], [6, 13], [6, 14], [7, 14], [6, 14], [6, 15], [6, 14], [5, 14], [6, 14], [6, 15], [6, 14], [6, 13], [7, 13], [6, 13], [6, 14], [5, 14], [6, 14], [6, 15], [6, 14], [7, 14], [6, 14], [6, 13], [6, 14], [5, 14], [6, 14], [6, 13], [6, 14], [7, 14], [6, 14], [6, 13], [5, 13], [5, 14], [6, 14], [6, 13], [6, 14], [5, 14], [6, 14], [6, 13], [6, 14], [5, 14], [6, 14], [6, 13], [6, 14], [6, 13], [5, 13], [6, 13], [6, 12], [6, 13], [5, 13], [5, 14], [6, 14], [6, 13], [5, 13], [5, 12]]\n",
      "[['0' '$' '0' '0' '0' '0' '0' '0' '0' '$' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '$']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '$' '0' '0' '0']\n",
      " ['0' '0' 'a' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '$' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '$' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']]\n",
      "litter picked up: 9\n",
      "[[4, 0], [3, 0], [2, 0], [2, 1], [1, 1], [1, 2], [2, 2], [2, 3], [2, 4], [3, 4], [2, 4], [3, 4], [3, 5], [2, 5], [3, 5], [3, 6], [2, 6], [3, 6], [3, 5], [3, 6], [2, 6], [1, 6], [2, 6], [1, 6], [2, 6], [2, 7], [1, 7], [1, 8], [1, 7], [2, 7], [1, 7], [1, 6], [1, 7], [1, 8], [0, 8], [1, 8], [1, 9], [1, 8], [1, 7], [1, 8], [0, 8], [0, 7], [0, 8], [0, 7], [0, 8], [1, 8], [1, 7], [1, 8], [0, 8], [1, 8], [1, 7], [1, 8], [0, 8], [0, 7], [1, 7], [0, 7], [0, 8], [0, 7], [0, 8], [1, 8], [0, 8], [0, 7], [0, 6], [0, 7], [1, 7], [0, 7], [0, 6], [0, 7], [0, 6], [0, 7], [0, 7], [1, 7], [1, 8], [1, 7], [0, 7], [0, 6], [0, 7], [0, 7], [0, 8], [1, 8], [1, 9], [1, 8], [1, 9], [1, 8], [2, 8], [3, 8], [4, 8], [4, 7], [5, 7], [6, 7], [6, 8], [7, 8], [7, 8], [7, 8], [7, 9], [7, 10], [7, 11], [7, 12], [7, 13], [7, 13], [7, 13], [7, 13], [7, 13], [7, 13], [7, 12], [7, 13], [7, 12], [7, 12], [7, 13], [6, 13], [6, 14], [7, 14], [7, 15], [7, 15], [7, 15], [7, 15], [7, 15], [7, 15], [7, 15], [7, 15], [7, 15], [6, 15], [6, 15], [6, 14], [6, 13], [7, 13], [7, 13], [7, 12], [7, 11], [7, 11], [7, 10], [7, 10], [7, 9], [7, 8], [7, 7], [6, 7], [5, 7], [5, 6], [5, 5], [5, 4], [5, 3], [4, 3], [4, 2], [5, 2], [5, 1], [6, 1], [6, 0], [6, 0], [6, 0], [5, 0], [5, 0], [5, 1], [5, 0], [4, 0], [4, 0], [3, 0], [4, 0], [4, 1], [5, 1], [5, 0], [4, 0], [5, 0], [6, 0], [5, 0], [5, 0], [5, 1], [5, 2], [5, 1], [5, 0], [4, 0], [4, 1], [5, 1], [4, 1], [5, 1], [5, 0], [5, 1], [4, 1], [4, 2], [4, 1], [5, 1], [4, 1], [5, 1], [5, 0], [5, 1], [4, 1], [5, 1], [5, 0], [5, 1], [5, 0], [5, 0], [5, 0], [4, 0], [4, 0], [5, 0], [5, 1], [4, 1], [5, 1], [5, 2], [5, 1], [4, 1], [4, 2]]\n",
      "[['$' '0' '0' '0' '0' '0' '0' '$' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '$' '0' '0' '0' '0' '0' '0' '0' '0' '0' '$' '$' '0' '0' '0']\n",
      " ['a' '0' '0' '0' '0' '0' '$' '$' '$' '0' '0' '0' '0' '0' '$' '0']\n",
      " ['0' '0' '0' '$' '0' '0' '0' '0' '$' '0' '0' '0' '0' '$' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '$' '0' '0' '$' '$' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '$' '0' '0' '0' '0' '0' '$' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '$']]\n",
      "[['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '$' '0' '0' '0' '0' '0' '$' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '$' '0' '0' '0' '0' '0' 'a' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '$' '0' '0' '0' '$' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '$' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']]\n",
      "litter picked up: 12\n",
      "[[2, 0], [1, 0], [0, 0], [1, 0], [1, 0], [1, 1], [2, 1], [2, 2], [3, 2], [3, 1], [3, 2], [3, 1], [3, 2], [3, 3], [3, 2], [3, 3], [2, 3], [3, 3], [4, 3], [4, 2], [4, 3], [4, 2], [4, 1], [3, 1], [4, 1], [3, 1], [3, 2], [3, 1], [4, 1], [4, 0], [4, 1], [3, 1], [4, 1], [4, 0], [4, 1], [3, 1], [3, 2], [3, 3], [4, 3], [5, 3], [4, 3], [4, 2], [4, 1], [4, 2], [3, 2], [4, 2], [4, 3], [5, 3], [5, 2], [5, 3], [4, 3], [4, 2], [5, 2], [4, 2], [4, 3], [4, 2], [5, 2], [4, 2], [4, 1], [4, 2], [5, 2], [4, 2], [4, 1], [4, 2], [5, 2], [4, 2], [4, 3], [4, 2], [5, 2], [4, 2], [4, 3], [3, 3], [3, 2], [4, 2], [4, 3], [4, 4], [3, 4], [4, 4], [3, 4], [2, 4], [1, 4], [2, 4], [2, 5], [2, 6], [1, 6], [0, 6], [0, 7], [1, 7], [2, 7], [3, 7], [2, 7], [1, 7], [1, 8], [1, 7], [1, 8], [1, 9], [1, 10], [2, 10], [2, 11], [1, 11], [1, 12], [0, 12], [0, 11], [0, 11], [0, 12], [1, 12], [2, 12], [2, 11], [3, 11], [2, 11], [2, 12], [2, 11], [3, 11], [3, 12], [3, 13], [3, 12], [2, 12], [2, 13], [1, 13], [1, 12], [2, 12], [2, 13], [3, 13], [2, 13], [3, 13], [3, 12], [3, 13], [3, 12], [2, 12], [2, 11], [2, 12], [2, 13], [2, 12], [1, 12], [2, 12], [2, 13], [3, 13], [3, 12], [3, 13], [3, 14], [3, 13], [3, 14], [3, 13], [3, 14], [3, 13], [4, 13], [3, 13], [4, 13], [4, 12], [5, 12], [6, 12], [7, 12], [6, 12], [7, 12], [6, 12], [5, 12], [6, 12], [6, 11], [5, 11], [5, 10], [6, 10], [5, 10], [5, 11], [5, 10], [6, 10], [5, 10], [4, 10], [5, 10], [6, 10], [7, 10], [7, 11], [7, 12], [6, 12], [7, 12], [6, 12], [6, 13], [5, 13], [5, 14], [6, 14], [7, 14], [7, 14], [7, 14], [7, 14], [7, 14], [6, 14], [6, 13], [6, 14], [7, 14], [7, 15], [7, 15], [7, 15], [7, 14], [7, 15], [6, 15], [6, 15], [6, 14], [5, 14], [5, 15], [4, 15], [4, 14], [3, 14]]\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 6000\n",
    "max_step = 200\n",
    "mu = 0.9\n",
    "gamma = 0.9\n",
    "epsilon = 0.3\n",
    "for num in range(num_episodes):\n",
    "    env, a_r = init_env()\n",
    "    environ_lit = env_extract_litter(env, a_r)\n",
    "    a_c = 0\n",
    "\n",
    "    # examine a certain environment in the last episode\n",
    "    if num == num_episodes - 1:\n",
    "        a_r = 2\n",
    "        environ_lit = np.array([['$','0','0','0','0','0','0','$','0','0','0','0','0','0','0','0'],\n",
    "                       ['0','$','0','0','0','0','0','0','0','0','0','$','$','0','0','0'],\n",
    "                       ['a','0','0','0','0','0','$','$','$','0','0','0','0','0','$','0'],\n",
    "                       ['0','0','0','$','0','0','0','0','$','0','0','0','0','$','0','0'],\n",
    "                       ['0','0','0','0','0','0','0','$','0','0','$','$','0','0','0','0'],\n",
    "                       ['0','0','0','0','0','0','0','0','$','0','0','0','0','0','$','0'],\n",
    "                       ['0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','0'],\n",
    "                       ['0','0','0','0','0','0','0','0','0','0','0','0','0','0','0','$']])\n",
    "        print(environ_lit)   \n",
    "    \n",
    "    loc = [[a_r, a_c]]\n",
    "    s = get_state_lit(environ_lit, a_r, a_c)\n",
    "    new_s = s\n",
    "    lit_num = 0\n",
    "\n",
    "    for j in range(max_step):\n",
    "        # epsilon-greedy algorithm\n",
    "        greedy = False\n",
    "        indices = 0\n",
    "\n",
    "        if np.random.rand() < epsilon:\n",
    "            indices = np.where(qtable_lit[s, :] >= -10)\n",
    "            if np.shape(indices)[1] != 0:\n",
    "                greedy = True\n",
    "\n",
    "        if greedy:\n",
    "            pick = np.random.randint(np.shape(indices)[1])\n",
    "            act = indices[0][pick]\n",
    "        else:\n",
    "            act = np.argmax(qtable_lit[s, :])\n",
    "\n",
    "        row = a_r + direct[act][0]\n",
    "        col = a_c + direct[act][1]\n",
    "        r = get_reward_lit(environ_lit, row, col)\n",
    "\n",
    "        # perform action\n",
    "        if act == 0:  # up\n",
    "            if not out_bound(a_r - 1, a_c):\n",
    "                environ_lit[a_r, a_c] = '0'\n",
    "                if is_litter(a_r - 1, a_c, environ_lit):\n",
    "                    lit_num += 1\n",
    "                environ_lit[a_r - 1, a_c] = 'a'\n",
    "                new_s = get_state_lit(environ_lit, a_r - 1, a_c)\n",
    "                a_r -= 1\n",
    "        if act == 1:  # right\n",
    "            if not out_bound(a_r, a_c + 1):\n",
    "                environ_lit[a_r, a_c] = '0'\n",
    "                if is_litter(a_r, a_c + 1, environ_lit):\n",
    "                    lit_num += 1\n",
    "                environ_lit[a_r, a_c + 1] = 'a'\n",
    "                new_s = get_state_lit(environ_lit, a_r, a_c + 1)\n",
    "                a_c += 1\n",
    "        if act == 2:  # down\n",
    "            if not out_bound(a_r + 1, a_c):\n",
    "                environ_lit[a_r, a_c] = '0'\n",
    "                if is_litter(a_r + 1, a_c, environ_lit):\n",
    "                    lit_num += 1\n",
    "                environ_lit[a_r + 1, a_c] = 'a'\n",
    "                new_s = get_state_lit(environ_lit, a_r + 1, a_c)\n",
    "                a_r += 1\n",
    "        if act == 3:  # left\n",
    "            if not out_bound(a_r, a_c - 1):\n",
    "                environ_lit[a_r, a_c] = '0'\n",
    "                if is_litter(a_r, a_c - 1, environ_lit):\n",
    "                    lit_num += 1\n",
    "                environ_lit[a_r, a_c - 1] = 'a'\n",
    "                new_s = get_state_lit(environ_lit, a_r, a_c - 1)\n",
    "                a_c -= 1\n",
    "\n",
    "        # update with Q-learning\n",
    "        loc.append([a_r, a_c])\n",
    "        qtable_lit[s, act] += mu * (r + gamma * max(qtable_lit[new_s, :]) - qtable_lit[s, act])\n",
    "        s = new_s\n",
    "\n",
    "    # print environment, number of litters picked up, and agent's trajectory in certain episode numbers\n",
    "    if num == 0 or num == num_episodes // 2 or num == num_episodes - 1:\n",
    "        print(environ_lit)\n",
    "        print('litter picked up:', lit_num)\n",
    "        print(loc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17408:\n",
      " [1781.1611148   978.77894189 1217.54158827 1305.17441914]\n",
      "\n",
      "128:\n",
      " [1033.58061145 1251.89254962  920.15501735  969.60627209]\n",
      "\n",
      "1:\n",
      " [ 786.8096416   808.45656036 1202.57500846  792.48011755]\n",
      "\n",
      "0:\n",
      " [ 532.45024762  563.13651379   18.76553255 1020.72930765]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print certain litter module state number and Q-table entries\n",
    "print(\"17408:\\n\", qtable_lit[17408,:])\n",
    "print()\n",
    "print(\"128:\\n\", qtable_lit[128,:])\n",
    "print()\n",
    "print(\"1:\\n\", qtable_lit[1,:])\n",
    "print()\n",
    "print(\"0:\\n\", qtable_lit[0,:])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Combined Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env_test:\n",
      " [['0' '0' 'x' '0' 'x' '0' 'x' '0' 'x' '0' 'x' '0' '0' '$' '0' '0']\n",
      " ['0' '0' 'x' 'x' '0' 'x' '0' '0' '0' '0' '$' '0' '0' '0' 'x' '$']\n",
      " ['a' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '$' '0' '0' '0' '$' 'x' '0' 'x' '0' 'x' '0' '$' '0']\n",
      " ['0' '0' '0' '0' '$' '0' '0' '0' '0' '0' '$' '0' '0' '0' '0' '0']\n",
      " ['x' '0' '$' '0' '0' '0' 'x' '0' '0' '0' '0' '$' 'x' '$' '0' '0']\n",
      " ['x' '0' 'x' '$' 'x' 'x' '0' '0' '0' '0' '$' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' 'x' '0' '0' '0' '0' '$' '$' '0' '0' '0' '0']]\n",
      "[[2, 0], [2, 1], [2, 2], [2, 3], [3, 3], [3, 4], [4, 4], [4, 5], [4, 6], [4, 7], [3, 7], [2, 7], [2, 8], [2, 9], [2, 10], [2, 11], [2, 12], [2, 13], [2, 14], [3, 14], [4, 14], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [4, 15], [5, 15]]\n",
      "[['0' '0' 'x' '0' 'x' '0' 'x' '0' 'x' '0' 'x' '0' '0' '$' '0' '0']\n",
      " ['0' '0' 'x' 'x' '0' 'x' '0' '0' '0' '0' '$' '0' '0' '0' 'x' '$']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' 'x' '0' 'x' '0' 'x' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '$' '0' '0' '0' '0' '0']\n",
      " ['x' '0' '$' '0' '0' '0' 'x' '0' '0' '0' '0' '$' 'x' '$' '0' 'a']\n",
      " ['x' '0' 'x' '$' 'x' 'x' '0' '0' '0' '0' '$' '0' '0' '0' '0' '0']\n",
      " ['0' '0' '0' '0' '0' 'x' '0' '0' '0' '0' '$' '$' '0' '0' '0' '0']]\n"
     ]
    }
   ],
   "source": [
    "# randomly generate an environment, set agent at [2,0] and goal at [5,15], and print it\n",
    "env_test, a_r = init_env(rand=2)\n",
    "env_test[5, 15] = '0'\n",
    "a_c = 0\n",
    "print('env_test:\\n', env_test)\n",
    "env_test_agent = env_extract(a_r)\n",
    "\n",
    "# walking\n",
    "num_steps = 60\n",
    "loc = [[a_r, a_c]]\n",
    "for i in range(num_steps):\n",
    "    if [a_r, a_c] == goal:\n",
    "        break\n",
    "\n",
    "    # get associated state numbers and Q-table entries from each module\n",
    "    s_sd = get_state_sd(a_r)\n",
    "    s_goal = get_state_goal(a_r, a_c)\n",
    "    s_obs = get_state_obs(env_test, a_r, a_c)\n",
    "    s_lit = get_state_lit(env_test, a_r, a_c)\n",
    "\n",
    "    q_sd = qtable_sidewalk[s_sd, :]\n",
    "    q_goal = qtable_goal[s_goal, :]\n",
    "    q_obs = qtable_obs[s_obs, :]\n",
    "    q_lit = qtable_lit[s_lit, :]\n",
    "\n",
    "    # combine Q-entries using weighted-sum (weights are different here depending on the total steps walked);\n",
    "    # there are many possible ways to combine or set threshold here\n",
    "    if i <= 40:\n",
    "        q_combined = 3*q_sd + 1.5*q_obs + 8*q_lit + q_goal\n",
    "    else:\n",
    "        q_combined = q_sd + 0.5*q_obs + q_lit + 5*q_goal\n",
    "\n",
    "    # act and update\n",
    "    act = np.argmax(q_combined)\n",
    "    new_r = a_r + direct[act][0]\n",
    "    new_c = a_c + direct[act][1]\n",
    "\n",
    "    if not out_bound(new_r, new_c):\n",
    "        a_r, a_c = new_r, new_c\n",
    "    if env_test[a_r, a_c] == '$':\n",
    "        env_test[a_r, a_c] = '0'\n",
    "\n",
    "    loc.append([a_r, a_c])\n",
    "\n",
    "    \n",
    "# print trajectory\n",
    "print(loc)\n",
    "\n",
    "# print the resulting environment\n",
    "env_final = np.empty(shape=(8, 16), dtype=str)\n",
    "env_final.fill('0')\n",
    "for i in range(8):\n",
    "    for j in range(16):\n",
    "        if env_test[i, j] == 'x':\n",
    "            env_final[i, j] = 'x'\n",
    "        elif env_test[i, j] == '$':\n",
    "            env_final[i, j] = '$'\n",
    "\n",
    "env_final[a_r, a_c] = 'a'\n",
    "print(env_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
